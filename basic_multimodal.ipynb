{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2361cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf  # aka fitz\n",
    "import uuid\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "import io\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct\n",
    "from qdrant_client.models import Distance, VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ef0e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_READ_TIMEOUT\"] = \"60\"\n",
    "os.environ[\"HF_HUB_CONNECT_TIMEOUT\"] = \"60\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0ec13c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 398/398 [00:01<00:00, 274.34it/s, Materializing param=visual_projection.weight]                                \n",
      "CLIPModel LOAD REPORT from: clip-ViT-B-32/0_CLIPModel\n",
      "Key                                  | Status     |  | \n",
      "-------------------------------------+------------+--+-\n",
      "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11c0e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_db():\n",
    "    client = QdrantClient(\"http://localhost:6333\")\n",
    "    if not client.collection_exists(collection_name=\"col_1\"):\n",
    "        client.create_collection(\n",
    "        collection_name=\"col_1\",\n",
    "        vectors_config=VectorParams(size=512, distance=Distance.COSINE)\n",
    "        )\n",
    "\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbca908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import uuid\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "def populate_db(doc_path, client):\n",
    "    model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "    doc = pymupdf.open(doc_path)\n",
    "\n",
    "    # -------- TEXT --------\n",
    "    for page_no, page in enumerate(doc):\n",
    "        page_text = page.get_text().strip()\n",
    "        if not page_text:\n",
    "            continue\n",
    "\n",
    "        text_embedding = model.encode(page_text).tolist()\n",
    "\n",
    "        client.upsert(\n",
    "            collection_name=\"col_1\",\n",
    "            points=[PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=text_embedding,\n",
    "                payload={\n",
    "                    \"page_no\": page_no,\n",
    "                    \"text\": page_text,\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            )]\n",
    "        )\n",
    "\n",
    "    # -------- IMAGES --------\n",
    "    os.makedirs(\"images\")\n",
    "\n",
    "    for page_no, page in enumerate(doc):\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "\n",
    "            base = doc.extract_image(xref)\n",
    "            image_bytes = base[\"image\"]\n",
    "            image_ext = base[\"ext\"]\n",
    "\n",
    "            filename = f\"{uuid.uuid4()}.{image_ext}\"\n",
    "            filepath = f\"images/{filename}\"\n",
    "\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "\n",
    "            pil_img = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "            image_embedding = model.encode(pil_img).tolist()\n",
    "\n",
    "            client.upsert(\n",
    "                collection_name=\"col_1\",\n",
    "                points=[PointStruct(\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    vector=image_embedding,\n",
    "                    payload={\n",
    "                        \"page_no\": page_no,\n",
    "                        \"filename\": filename,\n",
    "                        \"type\": \"image\"\n",
    "                    }\n",
    "                )]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61945f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk(client:QdrantClient, query_vector):\n",
    "\n",
    "    \"\"\"\n",
    "    Takes in a QdrantClient object and a query vector, and returns the top k nearest vectors to it\n",
    "    \"\"\"\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=\"col_1\",\n",
    "        query=query_vector,\n",
    "        limit=50\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f9ee71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(doc_path, query):\n",
    "\n",
    "    # DOC_PATH = '../docs/problem_statement.pdf'\n",
    "    \n",
    "    client = initialise_db()\n",
    "    populate_db(doc_path=doc_path, client=client)\n",
    "\n",
    "    model = SentenceTransformer('clip-ViT-B-32')\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    top_k = get_topk(client, query_embedding)\n",
    "\n",
    "    for item in top_k.points:\n",
    "        print(f\"page_no = {item.payload['page_no']}, score = {item.score}, type = {item.payload['type']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96db95e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 398/398 [00:01<00:00, 278.09it/s, Materializing param=visual_projection.weight]                                \n",
      "CLIPModel LOAD REPORT from: clip-ViT-B-32/0_CLIPModel\n",
      "Key                                  | Status     |  | \n",
      "-------------------------------------+------------+--+-\n",
      "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Loading weights: 100%|██████████| 398/398 [00:00<00:00, 653.51it/s, Materializing param=visual_projection.weight]                                \n",
      "CLIPModel LOAD REPORT from: clip-ViT-B-32/0_CLIPModel\n",
      "Key                                  | Status     |  | \n",
      "-------------------------------------+------------+--+-\n",
      "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_no = 15, score = 0.7725273, type = text \n",
      "\n",
      "page_no = 4, score = 0.7016804, type = text \n",
      "\n",
      "page_no = 3, score = 0.68394315, type = text \n",
      "\n",
      "page_no = 5, score = 0.67258656, type = text \n",
      "\n",
      "page_no = 6, score = 0.67138594, type = text \n",
      "\n",
      "page_no = 7, score = 0.66847545, type = text \n",
      "\n",
      "page_no = 8, score = 0.66141737, type = text \n",
      "\n",
      "page_no = 9, score = 0.6606197, type = text \n",
      "\n",
      "page_no = 12, score = 0.6599006, type = text \n",
      "\n",
      "page_no = 11, score = 0.6529188, type = text \n",
      "\n",
      "page_no = 13, score = 0.6067456, type = text \n",
      "\n",
      "page_no = 14, score = 0.5983734, type = text \n",
      "\n",
      "page_no = 0, score = 0.57742244, type = text \n",
      "\n",
      "page_no = 10, score = 0.54114044, type = text \n",
      "\n",
      "page_no = 2, score = 0.521142, type = text \n",
      "\n",
      "page_no = 1, score = 0.50299656, type = text \n",
      "\n",
      "page_no = 14, score = 0.26119924, type = image \n",
      "\n",
      "page_no = 2, score = 0.2580132, type = image \n",
      "\n",
      "page_no = 0, score = 0.25643256, type = image \n",
      "\n",
      "page_no = 4, score = 0.23159611, type = image \n",
      "\n",
      "page_no = 6, score = 0.22593552, type = image \n",
      "\n",
      "page_no = 7, score = 0.21584292, type = image \n",
      "\n",
      "page_no = 9, score = 0.2151424, type = image \n",
      "\n",
      "page_no = 3, score = 0.21441789, type = image \n",
      "\n",
      "page_no = 15, score = 0.21026167, type = image \n",
      "\n",
      "page_no = 11, score = 0.2094166, type = image \n",
      "\n",
      "page_no = 4, score = 0.20563805, type = image \n",
      "\n",
      "page_no = 11, score = 0.2031921, type = image \n",
      "\n",
      "page_no = 15, score = 0.20185395, type = image \n",
      "\n",
      "page_no = 15, score = 0.19732812, type = image \n",
      "\n",
      "page_no = 15, score = 0.19631861, type = image \n",
      "\n",
      "page_no = 15, score = 0.19335906, type = image \n",
      "\n",
      "page_no = 8, score = 0.19226806, type = image \n",
      "\n",
      "page_no = 13, score = 0.19000578, type = image \n",
      "\n",
      "page_no = 12, score = 0.18970715, type = image \n",
      "\n",
      "page_no = 15, score = 0.18464132, type = image \n",
      "\n",
      "page_no = 15, score = 0.18387294, type = image \n",
      "\n",
      "page_no = 12, score = 0.18209192, type = image \n",
      "\n",
      "page_no = 15, score = 0.177989, type = image \n",
      "\n",
      "page_no = 15, score = 0.17597531, type = image \n",
      "\n",
      "page_no = 5, score = 0.17506729, type = image \n",
      "\n",
      "page_no = 5, score = 0.17354517, type = image \n",
      "\n",
      "page_no = 10, score = 0.17247021, type = image \n",
      "\n",
      "page_no = 8, score = 0.16793418, type = image \n",
      "\n",
      "page_no = 9, score = 0.16662917, type = image \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('./docs/ss.pdf', 'green grass')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
